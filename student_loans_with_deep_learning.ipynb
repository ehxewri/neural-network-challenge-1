{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ZNhGcW6q6r"
      },
      "source": [
        "# Student Loan Risk with Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "0otrXpJc6q6u"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam, Adamax, Nadam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpV4Y-3Z6q6w"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 1: Prepare the data to be used on a neural network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUuSzp2l6q6w"
      },
      "source": [
        "### Step 1: Read the `student-loans.csv` file into a Pandas DataFrame. Review the DataFrame, looking for columns that could eventually define your features and target variables.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "G65km1KD6q6x",
        "outputId": "93d12d8d-c415-4017-8452-5b4966e4dde5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>payment_history</th>\n",
              "      <th>location_parameter</th>\n",
              "      <th>stem_degree_score</th>\n",
              "      <th>gpa_ranking</th>\n",
              "      <th>alumni_success</th>\n",
              "      <th>study_major_code</th>\n",
              "      <th>time_to_completion</th>\n",
              "      <th>finance_workshop_score</th>\n",
              "      <th>cohort_ranking</th>\n",
              "      <th>total_loan_score</th>\n",
              "      <th>financial_aid_score</th>\n",
              "      <th>credit_ranking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   payment_history  location_parameter  stem_degree_score  gpa_ranking  \\\n",
              "0              7.4                0.70               0.00          1.9   \n",
              "1              7.8                0.88               0.00          2.6   \n",
              "2              7.8                0.76               0.04          2.3   \n",
              "3             11.2                0.28               0.56          1.9   \n",
              "4              7.4                0.70               0.00          1.9   \n",
              "\n",
              "   alumni_success  study_major_code  time_to_completion  \\\n",
              "0           0.076              11.0                34.0   \n",
              "1           0.098              25.0                67.0   \n",
              "2           0.092              15.0                54.0   \n",
              "3           0.075              17.0                60.0   \n",
              "4           0.076              11.0                34.0   \n",
              "\n",
              "   finance_workshop_score  cohort_ranking  total_loan_score  \\\n",
              "0                  0.9978            3.51              0.56   \n",
              "1                  0.9968            3.20              0.68   \n",
              "2                  0.9970            3.26              0.65   \n",
              "3                  0.9980            3.16              0.58   \n",
              "4                  0.9978            3.51              0.56   \n",
              "\n",
              "   financial_aid_score  credit_ranking  \n",
              "0                  9.4               0  \n",
              "1                  9.8               0  \n",
              "2                  9.8               0  \n",
              "3                  9.8               1  \n",
              "4                  9.4               0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(1599, 12)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Read the csv into a Pandas DataFrame\n",
        "file_path = \"https://static.bc-edx.com/ai/ail-v-1-0/m18/lms/datasets/student-loans.csv\"\n",
        "loans_df = pd.read_csv(file_path)\n",
        "\n",
        "# Review the DataFrame\n",
        "display (loans_df.head())\n",
        "display (loans_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8ZYB8wx6q6x",
        "outputId": "b509fc34-4488-406e-e451-2069fec37371"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "payment_history           float64\n",
              "location_parameter        float64\n",
              "stem_degree_score         float64\n",
              "gpa_ranking               float64\n",
              "alumni_success            float64\n",
              "study_major_code          float64\n",
              "time_to_completion        float64\n",
              "finance_workshop_score    float64\n",
              "cohort_ranking            float64\n",
              "total_loan_score          float64\n",
              "financial_aid_score       float64\n",
              "credit_ranking              int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Review the data types associated with the columns\n",
        "loans_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P8aX-dW75JO",
        "outputId": "63251fa8-5ac1-4112-c2f7-bc5d97ea8491"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "credit_ranking\n",
              "1    855\n",
              "0    744\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array([0, 1], dtype=int64)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check the credit_ranking value counts\n",
        "display (loans_df[\"credit_ranking\"].value_counts())\n",
        "# another way of looking at the feature. not prefered as this does not show the count per class\n",
        "display (loans_df['credit_ranking'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6vbZeDH6q6y"
      },
      "source": [
        "### Step 2: Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “credit_ranking”. The remaining columns should define the features dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5eVAP5M6q6y",
        "outputId": "89728bbf-6930-4573-a126-9f1b66ed8859"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0], dtype=int64)"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the target set y using the credit_ranking column\n",
        "\n",
        "y = loans_df['credit_ranking']\n",
        "# Display a sample of y\n",
        "\n",
        "np.array(y)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "IIkrD2Sn6q6z",
        "outputId": "ce07c4a3-fb81-4657-d11e-ec85ae8554c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>payment_history</th>\n",
              "      <th>location_parameter</th>\n",
              "      <th>stem_degree_score</th>\n",
              "      <th>gpa_ranking</th>\n",
              "      <th>alumni_success</th>\n",
              "      <th>study_major_code</th>\n",
              "      <th>time_to_completion</th>\n",
              "      <th>finance_workshop_score</th>\n",
              "      <th>cohort_ranking</th>\n",
              "      <th>total_loan_score</th>\n",
              "      <th>financial_aid_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   payment_history  location_parameter  stem_degree_score  gpa_ranking  \\\n",
              "0              7.4                0.70               0.00          1.9   \n",
              "1              7.8                0.88               0.00          2.6   \n",
              "2              7.8                0.76               0.04          2.3   \n",
              "3             11.2                0.28               0.56          1.9   \n",
              "4              7.4                0.70               0.00          1.9   \n",
              "\n",
              "   alumni_success  study_major_code  time_to_completion  \\\n",
              "0           0.076              11.0                34.0   \n",
              "1           0.098              25.0                67.0   \n",
              "2           0.092              15.0                54.0   \n",
              "3           0.075              17.0                60.0   \n",
              "4           0.076              11.0                34.0   \n",
              "\n",
              "   finance_workshop_score  cohort_ranking  total_loan_score  \\\n",
              "0                  0.9978            3.51              0.56   \n",
              "1                  0.9968            3.20              0.68   \n",
              "2                  0.9970            3.26              0.65   \n",
              "3                  0.9980            3.16              0.58   \n",
              "4                  0.9978            3.51              0.56   \n",
              "\n",
              "   financial_aid_score  \n",
              "0                  9.4  \n",
              "1                  9.8  \n",
              "2                  9.8  \n",
              "3                  9.8  \n",
              "4                  9.4  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define features set X by selecting all columns but credit_ranking\n",
        "X=loans_df.drop(columns=['credit_ranking'])\n",
        "\n",
        "# Review the features DataFrame\n",
        "display (X.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmM9c-tj6q6z"
      },
      "source": [
        "### Step 3: Split the features and target sets into training and testing datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD7xwU_96q6z"
      },
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "# Assign the function a random_state equal to 1\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.2,random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assume X and y are your features and labels respectively\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)  # Split into training and temp (validation + test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9i6DHY06q6z"
      },
      "source": [
        "### Step 4: Use scikit-learn's `StandardScaler` to scale the features data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "BzD3z20m6q6z"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Step 2: Fit the scaler to the features training dataset\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Step 3: Transform the features training dataset\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "\n",
        "# Step 4: Transform the features testing dataset\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZzVDjba6q6z"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2 Compile and Evaluate a Model Using a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-pSux4Q6q60"
      },
      "source": [
        "### Step 1: Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
        "\n",
        "> **Hint** You can start with a two-layer deep neural network model that uses the `relu` activation function for both layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5C94FCd6q60",
        "outputId": "cbf05783-2f56-4745-cd33-649a6152e510"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Number of input features:'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the the number of inputs (features) to the model\n",
        "input_nodes  = X_train_scaled.shape[1]\n",
        "# or \n",
        "# input_nodes = len(X.columns)\n",
        "\n",
        "# Review the number of features\n",
        "display (\"Number of input features:\", input_nodes )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network Configuration Guide\n",
        "\n",
        "## 1. Define the Number of Hidden Nodes for the First Hidden Layer\n",
        "For the first hidden layer, a common approach is to start with a number of nodes that is somewhere between the number of input features and the number of output neurons. A typical strategy might be to use a number of nodes that is the mean or the geometric mean of these two numbers, adjusted based on the complexity of the problem or empirical testing.\n",
        "\n",
        "## 2. Define the Number of Hidden Nodes for the Second Hidden Layer\n",
        "For the second hidden layer, you might choose to reduce the number of nodes compared to the first hidden layer. This is often done to gradually reduce the dimensionality and to aggregate the features extracted by the first layer. A typical rule might be to halve the number of nodes in each subsequent layer, although the specific number should be tuned based on model performance and overfitting concerns.\n",
        "\n",
        "## 3. Define the Number of Neurons in the Output Layer\n",
        "The number of neurons in the output layer depends on the type of problem:\n",
        "\n",
        "- **Binary Classification**: Use 1 neuron with a sigmoid activation function.\n",
        "- **Multiclass Classification**: Use as many neurons as there are classes, with a softmax activation function.\n",
        "- **Regression**: Typically use 1 neuron for a single output; for multiple outputs, use as many neurons as there are outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "c_KXDLkF6q60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Number of hidden nodes for the first hidden layer  : 6'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Number of hidden nodes for the second hidden layer : 3'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Number of neurons in the output layer              : 1'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the number of hidden nodes for the first hidden layer\n",
        "num_nodes_first_hidden_layer = (input_nodes + 1) // 2  # Example calculation\n",
        "\n",
        "# Define the number of hidden nodes for the second hidden layer\n",
        "num_nodes_second_hidden_layer = num_nodes_first_hidden_layer // 2\n",
        "\n",
        "# For binary classification\n",
        "num_output_neurons = 1  # Using sigmoid activation\n",
        "# For multiclass classification (e.g., 3 classes)  num_output_neurons = 3  # Using softmax activation\n",
        "# For regression num_output_neurons = 1  # Typically with no activation (or linear activation)\n",
        "\n",
        "\n",
        "display (f'Number of hidden nodes for the first hidden layer  : {num_nodes_first_hidden_layer}')\n",
        "display (f'Number of hidden nodes for the second hidden layer : {num_nodes_second_hidden_layer}')\n",
        "display (f'Number of neurons in the output layer              : {num_output_neurons}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63UdFncw6q60"
      },
      "source": [
        "# Create the Sequential model instance\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first hidden layer\n",
        "model.add(Dense(units=num_nodes_first_hidden_layer, activation='relu', input_dim=input_nodes))\n",
        "\n",
        "# Add the second hidden layer\n",
        "model.add(Dense(units=num_nodes_second_hidden_layer, activation='relu'))\n",
        "\n",
        "# Add the output layer to the model specifying the number of output neurons and activation function\n",
        "model.add(Dense(num_output_neurons, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the Sequential model instance\n",
        "model = Sequential(name='Student_Loan_Model')\n",
        "\n",
        "# Add the first hidden layer with input dimension specified\n",
        "model.add(Dense(units=num_nodes_first_hidden_layer, activation='relu', input_dim=input_nodes, name='First_Hidden_Layer'))\n",
        "# model.add(BatchNormalization(name='BatchNorm_Layer_1'))  # Normalize the activations from the first hidden layer\n",
        "# model.add(Dropout(0.7, name='Dropout_Layer_1'))  # Dropout for regularization to prevent overfitting\n",
        "\n",
        "# Add the second hidden layer\n",
        "model.add(Dense(units=num_nodes_second_hidden_layer, activation='relu', name='Second_Hidden_Layer'))\n",
        "# model.add(BatchNormalization(name='BatchNorm_Layer_2'))  # Normalize the activations from the second hidden layer\n",
        "# model.add(Dropout(0.7, name='Dropout_Layer_2'))  # Additional dropout layer for regularization\n",
        "\n",
        "# Add the output layer\n",
        "# If this is a binary classification problem, use 'sigmoid'. If it's regression, no activation or 'linear' can be used.\n",
        "model.add(Dense(num_output_neurons, activation='sigmoid', name='Output_Layer'))  # Use 'linear' if it's a regression task\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Beoh4f_6q61",
        "outputId": "2e50f810-086b-4d89-bf7d-98afbe0d649d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Student_Loan_Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " First_Hidden_Layer (Dense)  (None, 6)                 72        \n",
            "                                                                 \n",
            " Second_Hidden_Layer (Dense)  (None, 3)                21        \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 97\n",
            "Trainable params: 97\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the Sequential model summary\n",
        "display (model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRqWGIRo6q61"
      },
      "source": [
        "### Step 2: Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "E-hZaeSn6q61"
      },
      "outputs": [],
      "source": [
        "# Compile the Sequential model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x25e8Idc6q61",
        "outputId": "e95946ba-23da-47a3-a1c1-5e9a2a484a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "7/7 [==============================] - 1s 34ms/step - loss: 0.6865 - accuracy: 0.6051 - val_loss: 0.6839 - val_accuracy: 0.6133\n",
            "Epoch 2/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6849 - accuracy: 0.6178 - val_loss: 0.6827 - val_accuracy: 0.6289\n",
            "Epoch 3/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6833 - accuracy: 0.6256 - val_loss: 0.6814 - val_accuracy: 0.6367\n",
            "Epoch 4/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.6373 - val_loss: 0.6801 - val_accuracy: 0.6406\n",
            "Epoch 5/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.6364 - val_loss: 0.6787 - val_accuracy: 0.6445\n",
            "Epoch 6/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6782 - accuracy: 0.6403 - val_loss: 0.6774 - val_accuracy: 0.6406\n",
            "Epoch 7/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.6481 - val_loss: 0.6761 - val_accuracy: 0.6445\n",
            "Epoch 8/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6744 - accuracy: 0.6588 - val_loss: 0.6744 - val_accuracy: 0.6602\n",
            "Epoch 9/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6724 - accuracy: 0.6549 - val_loss: 0.6726 - val_accuracy: 0.6758\n",
            "Epoch 10/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6705 - accuracy: 0.6647 - val_loss: 0.6707 - val_accuracy: 0.6680\n",
            "Epoch 11/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6683 - accuracy: 0.6725 - val_loss: 0.6688 - val_accuracy: 0.6758\n",
            "Epoch 12/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6661 - accuracy: 0.6696 - val_loss: 0.6668 - val_accuracy: 0.6914\n",
            "Epoch 13/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6639 - accuracy: 0.6647 - val_loss: 0.6648 - val_accuracy: 0.6992\n",
            "Epoch 14/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6617 - accuracy: 0.6696 - val_loss: 0.6627 - val_accuracy: 0.7031\n",
            "Epoch 15/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6594 - accuracy: 0.6716 - val_loss: 0.6606 - val_accuracy: 0.7031\n",
            "Epoch 16/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6569 - accuracy: 0.6725 - val_loss: 0.6585 - val_accuracy: 0.7109\n",
            "Epoch 17/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.6804 - val_loss: 0.6562 - val_accuracy: 0.7109\n",
            "Epoch 18/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6521 - accuracy: 0.6823 - val_loss: 0.6537 - val_accuracy: 0.7148\n",
            "Epoch 19/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6492 - accuracy: 0.6804 - val_loss: 0.6511 - val_accuracy: 0.7188\n",
            "Epoch 20/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6462 - accuracy: 0.6804 - val_loss: 0.6485 - val_accuracy: 0.7227\n",
            "Epoch 21/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6432 - accuracy: 0.6813 - val_loss: 0.6456 - val_accuracy: 0.7266\n",
            "Epoch 22/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6399 - accuracy: 0.6843 - val_loss: 0.6427 - val_accuracy: 0.7266\n",
            "Epoch 23/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6366 - accuracy: 0.6872 - val_loss: 0.6396 - val_accuracy: 0.7305\n",
            "Epoch 24/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6328 - accuracy: 0.6891 - val_loss: 0.6364 - val_accuracy: 0.7344\n",
            "Epoch 25/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.6852 - val_loss: 0.6328 - val_accuracy: 0.7383\n",
            "Epoch 26/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6252 - accuracy: 0.6911 - val_loss: 0.6291 - val_accuracy: 0.7344\n",
            "Epoch 27/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.6940 - val_loss: 0.6254 - val_accuracy: 0.7461\n",
            "Epoch 28/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6164 - accuracy: 0.7009 - val_loss: 0.6216 - val_accuracy: 0.7539\n",
            "Epoch 29/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6120 - accuracy: 0.7058 - val_loss: 0.6176 - val_accuracy: 0.7500\n",
            "Epoch 30/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6070 - accuracy: 0.7097 - val_loss: 0.6136 - val_accuracy: 0.7500\n",
            "Epoch 31/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6020 - accuracy: 0.7136 - val_loss: 0.6097 - val_accuracy: 0.7422\n",
            "Epoch 32/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5969 - accuracy: 0.7195 - val_loss: 0.6060 - val_accuracy: 0.7461\n",
            "Epoch 33/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.7283 - val_loss: 0.6022 - val_accuracy: 0.7500\n",
            "Epoch 34/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5871 - accuracy: 0.7283 - val_loss: 0.5985 - val_accuracy: 0.7422\n",
            "Epoch 35/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5820 - accuracy: 0.7283 - val_loss: 0.5948 - val_accuracy: 0.7422\n",
            "Epoch 36/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.7312 - val_loss: 0.5913 - val_accuracy: 0.7344\n",
            "Epoch 37/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5723 - accuracy: 0.7331 - val_loss: 0.5879 - val_accuracy: 0.7266\n",
            "Epoch 38/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.7361 - val_loss: 0.5845 - val_accuracy: 0.7305\n",
            "Epoch 39/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.7351 - val_loss: 0.5814 - val_accuracy: 0.7344\n",
            "Epoch 40/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5589 - accuracy: 0.7410 - val_loss: 0.5786 - val_accuracy: 0.7344\n",
            "Epoch 41/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7439 - val_loss: 0.5761 - val_accuracy: 0.7344\n",
            "Epoch 42/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5514 - accuracy: 0.7458 - val_loss: 0.5739 - val_accuracy: 0.7344\n",
            "Epoch 43/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5480 - accuracy: 0.7478 - val_loss: 0.5719 - val_accuracy: 0.7344\n",
            "Epoch 44/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7488 - val_loss: 0.5700 - val_accuracy: 0.7344\n",
            "Epoch 45/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7507 - val_loss: 0.5683 - val_accuracy: 0.7344\n",
            "Epoch 46/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.7498 - val_loss: 0.5668 - val_accuracy: 0.7344\n",
            "Epoch 47/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7478 - val_loss: 0.5655 - val_accuracy: 0.7344\n",
            "Epoch 48/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7478 - val_loss: 0.5643 - val_accuracy: 0.7344\n",
            "Epoch 49/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.7468 - val_loss: 0.5631 - val_accuracy: 0.7305\n",
            "Epoch 50/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5304 - accuracy: 0.7478 - val_loss: 0.5619 - val_accuracy: 0.7305\n",
            "Epoch 51/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7449 - val_loss: 0.5610 - val_accuracy: 0.7305\n",
            "Epoch 52/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7478 - val_loss: 0.5602 - val_accuracy: 0.7305\n",
            "Epoch 53/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7478 - val_loss: 0.5592 - val_accuracy: 0.7305\n",
            "Epoch 54/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7488 - val_loss: 0.5586 - val_accuracy: 0.7344\n",
            "Epoch 55/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.7488 - val_loss: 0.5578 - val_accuracy: 0.7344\n",
            "Epoch 56/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.7478 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 57/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7468 - val_loss: 0.5568 - val_accuracy: 0.7266\n",
            "Epoch 58/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7439 - val_loss: 0.5565 - val_accuracy: 0.7266\n",
            "Epoch 59/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7449 - val_loss: 0.5559 - val_accuracy: 0.7266\n",
            "Epoch 60/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7458 - val_loss: 0.5554 - val_accuracy: 0.7266\n",
            "Epoch 61/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.7468 - val_loss: 0.5550 - val_accuracy: 0.7266\n",
            "Epoch 62/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7458 - val_loss: 0.5547 - val_accuracy: 0.7266\n",
            "Epoch 63/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7478 - val_loss: 0.5545 - val_accuracy: 0.7305\n",
            "Epoch 64/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.7468 - val_loss: 0.5541 - val_accuracy: 0.7305\n",
            "Epoch 65/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7458 - val_loss: 0.5540 - val_accuracy: 0.7305\n",
            "Epoch 66/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7458 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
            "Epoch 67/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7468 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
            "Epoch 68/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.7478 - val_loss: 0.5537 - val_accuracy: 0.7344\n",
            "Epoch 69/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7468 - val_loss: 0.5536 - val_accuracy: 0.7383\n",
            "Epoch 70/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.7458 - val_loss: 0.5536 - val_accuracy: 0.7383\n",
            "Epoch 71/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7468 - val_loss: 0.5535 - val_accuracy: 0.7383\n",
            "Epoch 72/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7478 - val_loss: 0.5535 - val_accuracy: 0.7383\n",
            "Epoch 73/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7488 - val_loss: 0.5535 - val_accuracy: 0.7383\n",
            "Epoch 74/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5083 - accuracy: 0.7488 - val_loss: 0.5536 - val_accuracy: 0.7383\n",
            "Epoch 75/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5078 - accuracy: 0.7468 - val_loss: 0.5534 - val_accuracy: 0.7422\n",
            "Epoch 76/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7468 - val_loss: 0.5532 - val_accuracy: 0.7422\n",
            "Epoch 77/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.7468 - val_loss: 0.5532 - val_accuracy: 0.7422\n",
            "Epoch 78/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7488 - val_loss: 0.5533 - val_accuracy: 0.7422\n",
            "Epoch 79/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7488 - val_loss: 0.5533 - val_accuracy: 0.7422\n",
            "Epoch 80/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.7468 - val_loss: 0.5534 - val_accuracy: 0.7422\n",
            "Epoch 81/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5053 - accuracy: 0.7478 - val_loss: 0.5533 - val_accuracy: 0.7422\n",
            "Epoch 82/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5049 - accuracy: 0.7498 - val_loss: 0.5533 - val_accuracy: 0.7422\n",
            "Epoch 83/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.7488 - val_loss: 0.5532 - val_accuracy: 0.7422\n",
            "Epoch 84/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7507 - val_loss: 0.5532 - val_accuracy: 0.7422\n",
            "Epoch 85/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7507 - val_loss: 0.5531 - val_accuracy: 0.7461\n",
            "Epoch 86/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7458 - val_loss: 0.5529 - val_accuracy: 0.7461\n",
            "Epoch 87/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7458 - val_loss: 0.5529 - val_accuracy: 0.7461\n",
            "Epoch 88/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7488 - val_loss: 0.5529 - val_accuracy: 0.7461\n",
            "Epoch 89/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.7498 - val_loss: 0.5528 - val_accuracy: 0.7461\n",
            "Epoch 90/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7527 - val_loss: 0.5528 - val_accuracy: 0.7461\n",
            "Epoch 91/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7546 - val_loss: 0.5528 - val_accuracy: 0.7422\n",
            "Epoch 92/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.7556 - val_loss: 0.5525 - val_accuracy: 0.7422\n",
            "Epoch 93/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7556 - val_loss: 0.5527 - val_accuracy: 0.7422\n",
            "Epoch 94/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7546 - val_loss: 0.5528 - val_accuracy: 0.7422\n",
            "Epoch 95/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7537 - val_loss: 0.5528 - val_accuracy: 0.7422\n",
            "Epoch 96/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7556 - val_loss: 0.5527 - val_accuracy: 0.7422\n",
            "Epoch 97/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7527 - val_loss: 0.5526 - val_accuracy: 0.7422\n",
            "Epoch 98/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7527 - val_loss: 0.5529 - val_accuracy: 0.7422\n",
            "Epoch 99/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7527 - val_loss: 0.5529 - val_accuracy: 0.7422\n",
            "Epoch 100/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7517 - val_loss: 0.5526 - val_accuracy: 0.7422\n",
            "Epoch 101/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7527 - val_loss: 0.5526 - val_accuracy: 0.7422\n",
            "Epoch 102/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7517 - val_loss: 0.5523 - val_accuracy: 0.7422\n",
            "Epoch 103/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.4978 - accuracy: 0.7507 - val_loss: 0.5520 - val_accuracy: 0.7422\n",
            "Epoch 104/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4974 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.7422\n",
            "Epoch 105/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7517 - val_loss: 0.5520 - val_accuracy: 0.7422\n",
            "Epoch 106/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7527 - val_loss: 0.5519 - val_accuracy: 0.7422\n",
            "Epoch 107/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7527 - val_loss: 0.5521 - val_accuracy: 0.7422\n",
            "Epoch 108/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7517 - val_loss: 0.5520 - val_accuracy: 0.7422\n",
            "Epoch 109/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7517 - val_loss: 0.5522 - val_accuracy: 0.7422\n",
            "Epoch 110/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7527 - val_loss: 0.5522 - val_accuracy: 0.7422\n",
            "Epoch 111/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7517 - val_loss: 0.5519 - val_accuracy: 0.7461\n",
            "Epoch 112/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7537 - val_loss: 0.5517 - val_accuracy: 0.7461\n",
            "Epoch 113/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7527 - val_loss: 0.5517 - val_accuracy: 0.7461\n",
            "Epoch 114/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7546 - val_loss: 0.5517 - val_accuracy: 0.7461\n",
            "Epoch 115/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7546 - val_loss: 0.5515 - val_accuracy: 0.7461\n",
            "Epoch 116/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7556 - val_loss: 0.5512 - val_accuracy: 0.7461\n",
            "Epoch 117/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7566 - val_loss: 0.5512 - val_accuracy: 0.7461\n",
            "Epoch 118/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7576 - val_loss: 0.5512 - val_accuracy: 0.7461\n",
            "Epoch 119/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7576 - val_loss: 0.5512 - val_accuracy: 0.7461\n",
            "Epoch 120/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7595 - val_loss: 0.5513 - val_accuracy: 0.7500\n",
            "Epoch 121/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7586 - val_loss: 0.5513 - val_accuracy: 0.7500\n",
            "Epoch 122/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7595 - val_loss: 0.5512 - val_accuracy: 0.7500\n",
            "Epoch 123/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7595 - val_loss: 0.5513 - val_accuracy: 0.7500\n",
            "Epoch 124/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7605 - val_loss: 0.5512 - val_accuracy: 0.7500\n",
            "Epoch 125/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7605 - val_loss: 0.5512 - val_accuracy: 0.7539\n",
            "Epoch 126/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7595 - val_loss: 0.5511 - val_accuracy: 0.7539\n",
            "Epoch 127/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7595 - val_loss: 0.5512 - val_accuracy: 0.7539\n",
            "Epoch 128/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7595 - val_loss: 0.5514 - val_accuracy: 0.7578\n",
            "Epoch 129/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7595 - val_loss: 0.5514 - val_accuracy: 0.7578\n",
            "Epoch 130/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7595 - val_loss: 0.5512 - val_accuracy: 0.7578\n",
            "Epoch 131/150\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4915 - accuracy: 0.7595 - val_loss: 0.5515 - val_accuracy: 0.7578\n",
            "Epoch 132/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7595 - val_loss: 0.5517 - val_accuracy: 0.7578\n",
            "Epoch 133/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7595 - val_loss: 0.5517 - val_accuracy: 0.7539\n",
            "Epoch 134/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.7595 - val_loss: 0.5517 - val_accuracy: 0.7578\n",
            "Epoch 135/150\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7595 - val_loss: 0.5521 - val_accuracy: 0.7578\n",
            "Epoch 136/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7595 - val_loss: 0.5518 - val_accuracy: 0.7539\n"
          ]
        }
      ],
      "source": [
        "# Fit the model using 50 epochs and the training data\n",
        "fit_model = model.fit(X_train_scaled, y_train, \n",
        "                      epochs=150, \n",
        "                      batch_size=150,\n",
        "                      # class_weight=class_weight_dict, \n",
        "                      validation_split=(0.2),\n",
        "                      callbacks=[early_stopping])\n",
        "                   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfHMPZVI6q61"
      },
      "source": [
        "### Step 3: Evaluate the model using the test data to determine the model’s loss and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hfVADKo6q61",
        "outputId": "7df473ad-3301-4b49-e5c3-16e1687cc1cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.5245\n",
            "Test Accuracy: 74.6875%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "\n",
        "# Display the model loss and accuracy results\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': [0.6864959001541138, 0.6848676800727844, 0.6832515597343445, 0.6816886067390442, 0.680065393447876, 0.6781668066978455, 0.6762340664863586, 0.674435555934906, 0.6724426746368408, 0.6705082058906555, 0.6682818531990051, 0.6660747528076172, 0.6638701558113098, 0.6616989970207214, 0.6593522429466248, 0.6569123864173889, 0.6544843316078186, 0.6520752310752869, 0.649249792098999, 0.6461945176124573, 0.6432160139083862, 0.6399233341217041, 0.6365868449211121, 0.6328328251838684, 0.6291282773017883, 0.625190794467926, 0.6209637522697449, 0.6163829565048218, 0.611964762210846, 0.6069644689559937, 0.601994514465332, 0.5969362854957581, 0.5920389294624329, 0.5870833396911621, 0.5820267200469971, 0.5770381093025208, 0.5723134279251099, 0.5676057934761047, 0.5631141662597656, 0.5589017271995544, 0.5549337267875671, 0.5514207482337952, 0.5479975938796997, 0.5446577668190002, 0.5418633818626404, 0.5389493703842163, 0.5364855527877808, 0.5342528223991394, 0.5322376489639282, 0.5303707122802734, 0.5283693671226501, 0.5268542170524597, 0.525185227394104, 0.5238010287284851, 0.5225471258163452, 0.5213596820831299, 0.5202714204788208, 0.5191724896430969, 0.5181465148925781, 0.5172148942947388, 0.5163066983222961, 0.5153853893280029, 0.5149017572402954, 0.5138571262359619, 0.5132889151573181, 0.5126330852508545, 0.5119450092315674, 0.5114393830299377, 0.5108922123908997, 0.5101980566978455, 0.5096668004989624, 0.5092868208885193, 0.5087674260139465, 0.5082646608352661, 0.5078221559524536, 0.507422149181366, 0.506960391998291, 0.5065803527832031, 0.5061624646186829, 0.5056930184364319, 0.5052962303161621, 0.5049189925193787, 0.5044721961021423, 0.5041284561157227, 0.5037590265274048, 0.5033883452415466, 0.5030359625816345, 0.5027421116828918, 0.5022686123847961, 0.501915693283081, 0.5015748143196106, 0.5012697577476501, 0.5008779764175415, 0.5005049109458923, 0.5001826882362366, 0.4998902976512909, 0.499527245759964, 0.49921393394470215, 0.4988575875759125, 0.498518705368042, 0.498249888420105, 0.4980292022228241, 0.4978269040584564, 0.4974265694618225, 0.4971517026424408, 0.49701541662216187, 0.4966844618320465, 0.49633750319480896, 0.4961990416049957, 0.4959363043308258, 0.4956783354282379, 0.49547821283340454, 0.49517396092414856, 0.4949803948402405, 0.49469107389450073, 0.4945398271083832, 0.4942263662815094, 0.49412378668785095, 0.4938579797744751, 0.49358758330345154, 0.493394136428833, 0.49317944049835205, 0.49295666813850403, 0.4927835464477539, 0.49258220195770264, 0.4923762381076813, 0.49222421646118164, 0.492007851600647, 0.49183377623558044, 0.4917663335800171, 0.4915328323841095, 0.4913622736930847, 0.4911465048789978, 0.49094533920288086, 0.49085548520088196, 0.49065136909484863], 'accuracy': [0.6050831079483032, 0.6177908182144165, 0.6256109476089478, 0.6373411417007446, 0.6363636255264282, 0.6402736902236938, 0.6480938196182251, 0.6588465571403503, 0.6549364328384399, 0.6647116541862488, 0.67253178358078, 0.6695992350578308, 0.6647116541862488, 0.6695992350578308, 0.6715542674064636, 0.67253178358078, 0.6803519129753113, 0.6823069453239441, 0.6803519129753113, 0.6803519129753113, 0.6813294291496277, 0.6842619776725769, 0.6871945261955261, 0.6891495585441589, 0.6852394938468933, 0.6911045908927917, 0.694037139415741, 0.7008797526359558, 0.7057673335075378, 0.7096773982048035, 0.7135874629020691, 0.7194526195526123, 0.72825026512146, 0.72825026512146, 0.72825026512146, 0.7311828136444092, 0.733137845993042, 0.7360703945159912, 0.7350928783416748, 0.7409579753875732, 0.7438905239105225, 0.7458455562591553, 0.7478005886077881, 0.7487781047821045, 0.7507331371307373, 0.7497556209564209, 0.7478005886077881, 0.7478005886077881, 0.7468230724334717, 0.7478005886077881, 0.7448680400848389, 0.7478005886077881, 0.7478005886077881, 0.7487781047821045, 0.7487781047821045, 0.7478005886077881, 0.7468230724334717, 0.7438905239105225, 0.7448680400848389, 0.7458455562591553, 0.7468230724334717, 0.7458455562591553, 0.7478005886077881, 0.7468230724334717, 0.7458455562591553, 0.7458455562591553, 0.7468230724334717, 0.7478005886077881, 0.7468230724334717, 0.7458455562591553, 0.7468230724334717, 0.7478005886077881, 0.7487781047821045, 0.7487781047821045, 0.7468230724334717, 0.7468230724334717, 0.7468230724334717, 0.7487781047821045, 0.7487781047821045, 0.7468230724334717, 0.7478005886077881, 0.7497556209564209, 0.7487781047821045, 0.7507331371307373, 0.7507331371307373, 0.7458455562591553, 0.7458455562591553, 0.7487781047821045, 0.7497556209564209, 0.7526881694793701, 0.7546432018280029, 0.7556207180023193, 0.7556207180023193, 0.7546432018280029, 0.7536656856536865, 0.7556207180023193, 0.7526881694793701, 0.7526881694793701, 0.7526881694793701, 0.7517106533050537, 0.7526881694793701, 0.7517106533050537, 0.7507331371307373, 0.7517106533050537, 0.7517106533050537, 0.7526881694793701, 0.7526881694793701, 0.7517106533050537, 0.7517106533050537, 0.7526881694793701, 0.7517106533050537, 0.7536656856536865, 0.7526881694793701, 0.7546432018280029, 0.7546432018280029, 0.7556207180023193, 0.7565982341766357, 0.7575757503509521, 0.7575757503509521, 0.759530782699585, 0.7585532665252686, 0.759530782699585, 0.759530782699585, 0.7605082988739014, 0.7605082988739014, 0.759530782699585, 0.759530782699585, 0.759530782699585, 0.759530782699585, 0.759530782699585, 0.759530782699585, 0.759530782699585, 0.759530782699585, 0.759530782699585, 0.759530782699585, 0.759530782699585], 'val_loss': [0.6839381456375122, 0.6826906204223633, 0.6813637018203735, 0.6800684928894043, 0.6787288188934326, 0.6774262189865112, 0.676059365272522, 0.6743738651275635, 0.6726080179214478, 0.6707170605659485, 0.6687580943107605, 0.6667764782905579, 0.6648240089416504, 0.6627453565597534, 0.6606203317642212, 0.6585094332695007, 0.6562442779541016, 0.6537097096443176, 0.6510908603668213, 0.6484614014625549, 0.6456263065338135, 0.642676055431366, 0.639553427696228, 0.6363531351089478, 0.6328121423721313, 0.6290990114212036, 0.6253613233566284, 0.6215933561325073, 0.617561936378479, 0.613595187664032, 0.609707236289978, 0.6059526205062866, 0.6021978259086609, 0.5984600782394409, 0.5948126912117004, 0.5913262367248535, 0.587873101234436, 0.5845396518707275, 0.581375777721405, 0.5785565376281738, 0.5761486291885376, 0.5738756656646729, 0.5718666315078735, 0.569989025592804, 0.568266749382019, 0.5668458938598633, 0.5655338168144226, 0.5642861723899841, 0.5631338357925415, 0.5619483590126038, 0.5610325336456299, 0.5601931810379028, 0.5592483282089233, 0.5585851669311523, 0.5578247308731079, 0.557269811630249, 0.5568476915359497, 0.5565169453620911, 0.5558900833129883, 0.5554032921791077, 0.5549935102462769, 0.5546985268592834, 0.5544544458389282, 0.5541291236877441, 0.5539658069610596, 0.5537607669830322, 0.5535959005355835, 0.5537455677986145, 0.5536421537399292, 0.5536036491394043, 0.5534997582435608, 0.5534891486167908, 0.5534879565238953, 0.5535972118377686, 0.5534094572067261, 0.5532088279724121, 0.5532258749008179, 0.5532954335212708, 0.5532804727554321, 0.5533596277236938, 0.553282618522644, 0.5532791614532471, 0.5532135367393494, 0.553226113319397, 0.5531419515609741, 0.5529025793075562, 0.5529392957687378, 0.5529101490974426, 0.5527546405792236, 0.5528000593185425, 0.5527543425559998, 0.5525344014167786, 0.5527071356773376, 0.5528102517127991, 0.5528459548950195, 0.5527245998382568, 0.55263751745224, 0.5528558492660522, 0.5528934001922607, 0.5526298880577087, 0.5525544881820679, 0.55226069688797, 0.5520320534706116, 0.5519262552261353, 0.5519852638244629, 0.551866352558136, 0.5520750880241394, 0.5520451068878174, 0.5522313714027405, 0.5522094964981079, 0.5519266724586487, 0.5516724586486816, 0.5516728758811951, 0.5517199039459229, 0.5514622330665588, 0.5512218475341797, 0.551169753074646, 0.5511701703071594, 0.5511631369590759, 0.5512899160385132, 0.5513181090354919, 0.5511685013771057, 0.5512577295303345, 0.551162600517273, 0.5512316226959229, 0.5510692596435547, 0.5512100458145142, 0.5513587594032288, 0.551437258720398, 0.5511819124221802, 0.5514909029006958, 0.5516557097434998, 0.5517102479934692, 0.5517446994781494, 0.5520733594894409, 0.5517635941505432], 'val_accuracy': [0.61328125, 0.62890625, 0.63671875, 0.640625, 0.64453125, 0.640625, 0.64453125, 0.66015625, 0.67578125, 0.66796875, 0.67578125, 0.69140625, 0.69921875, 0.703125, 0.703125, 0.7109375, 0.7109375, 0.71484375, 0.71875, 0.72265625, 0.7265625, 0.7265625, 0.73046875, 0.734375, 0.73828125, 0.734375, 0.74609375, 0.75390625, 0.75, 0.75, 0.7421875, 0.74609375, 0.75, 0.7421875, 0.7421875, 0.734375, 0.7265625, 0.73046875, 0.734375, 0.734375, 0.734375, 0.734375, 0.734375, 0.734375, 0.734375, 0.734375, 0.734375, 0.734375, 0.73046875, 0.73046875, 0.73046875, 0.73046875, 0.73046875, 0.734375, 0.734375, 0.734375, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.73046875, 0.73046875, 0.73046875, 0.734375, 0.734375, 0.734375, 0.73828125, 0.73828125, 0.73828125, 0.73828125, 0.73828125, 0.73828125, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.74609375, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75390625, 0.75390625, 0.75390625, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.75390625, 0.7578125, 0.7578125, 0.75390625]}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(fit_model.history)\n",
        "print (fit_model.history)\n",
        "\n",
        "# Increase the index by 1 to match the number of epochs\n",
        "history_df.index += 1\n",
        "\n",
        "# Plot the loss\n",
        "history_df.plot(y=\"loss\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpAv0rXA6q61"
      },
      "source": [
        "### Step 4: Save and export your model to a keras file, and name the file `student_loans.keras`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "q0MetN0W6q61"
      },
      "outputs": [],
      "source": [
        "# Set the model's file path\n",
        "file_path = Path(\"./resources/student_loans.keras\")\n",
        "\n",
        "# Export your model to a keras file\n",
        "model.save(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1opCDdN6q61"
      },
      "source": [
        "---\n",
        "## Predict Loan Repayment Success by Using your Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfIfpeiy6q61"
      },
      "source": [
        "### Step 1: Reload your saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "OCET2mvW6q61"
      },
      "outputs": [],
      "source": [
        "# Set the model's file path\n",
        "file_path = Path(\"./resources/student_loans.keras\")\n",
        "\n",
        "# Load the model to a new object\n",
        "lr_model = load_model(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPKooGw6q61"
      },
      "source": [
        "### Step 2: Make predictions on the testing data and save the predictions to a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vet7qjgx6q62",
        "outputId": "0925af42-7e12-4978-8396-2a2c1580e1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.56772184]\n",
            " [0.29440048]\n",
            " [0.77438086]\n",
            " [0.7342451 ]\n",
            " [0.9605413 ]]\n"
          ]
        }
      ],
      "source": [
        "# Make predictions with the test data\n",
        "predictions = lr_model.predict(X_test_scaled,verbose=0)\n",
        "\n",
        "\n",
        "# Display a sample of the predictions\n",
        "print (predictions[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "87o8exFPhjfl",
        "outputId": "da5339c5-cea7-43e4-ec22-e168ea16dfa2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted_Probability</th>\n",
              "      <th>Predicted_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.567722</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.294400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.774381</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.734245</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.960541</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Predicted_Probability  Predicted_Class\n",
              "0               0.567722                1\n",
              "1               0.294400                0\n",
              "2               0.774381                1\n",
              "3               0.734245                1\n",
              "4               0.960541                1"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the predictions to a DataFrame and round the predictions to binary results\n",
        "predictions_df = pd.DataFrame(data=predictions, columns=['Predicted_Probability'])\n",
        "# Round predictions to binary results (0 or 1) using 0.5 as the threshold\n",
        "predictions_df['Predicted_Class'] = np.where(predictions_df['Predicted_Probability'] >= 0.5, 1, 0)\n",
        "predictions_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxxLwycg6q62"
      },
      "source": [
        "### Step 4: Display a classification report with the y test data and predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTxYZibW6q67",
        "outputId": "f341b396-9b4c-478c-dba8-f6d904ba10e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.75      0.74       154\n",
            "           1       0.76      0.74      0.75       166\n",
            "\n",
            "    accuracy                           0.75       320\n",
            "   macro avg       0.75      0.75      0.75       320\n",
            "weighted avg       0.75      0.75      0.75       320\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the classification report with the y test data and predictions\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, predictions_df['Predicted_Class'].values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Describe the data that you would need to collect to build a recommendation system to recommend student loan options for students. Explain why this data would be relevant and appropriate.\n",
        "\n",
        "To build a recommendation system for student loan options, you would need to collect the following data:\n",
        "\n",
        "1. **Student Information:**\n",
        "   - **Demographics:** Age, gender, location, etc.\n",
        "   - **Academic Information:** Current school, major, GPA, year of study.\n",
        "   - **Financial Background:** Income level, employment status, credit score (if applicable), financial aid received.\n",
        "\n",
        "2. **Loan Details:**\n",
        "   - **Loan Types:** Federal loans, private loans, subsidized loans, unsubsidized loans.\n",
        "   - **Interest Rates:** Fixed vs. variable rates, APRs.\n",
        "   - **Loan Terms:** Duration of the loan, repayment plans, grace periods.\n",
        "   - **Eligibility Criteria:** Credit score requirements, co-signer requirements, income thresholds.\n",
        "\n",
        "3. **Historical Data:**\n",
        "   - **Previous Loan Data:** Past loans taken by students, repayment histories.\n",
        "   - **Default Rates:** Statistics on default rates for different loan types and lenders.\n",
        "   - **Success Stories:** Case studies or testimonials from students who have successfully repaid their loans.\n",
        "\n",
        "4. **External Factors:**\n",
        "   - **Economic Indicators:** Unemployment rates, inflation rates, average starting salaries for various fields.\n",
        "   - **Legislation:** Current student loan policies, upcoming changes in legislation.\n",
        "\n",
        "#### Relevance and Appropriateness:\n",
        "- **Student Information:** Helps tailor recommendations to individual needs and circumstances.\n",
        "- **Loan Details:** Essential for matching students with the most suitable loan options based on their financial situation.\n",
        "- **Historical Data:** Provides insights into the performance and reliability of different loan types and lenders.\n",
        "- **External Factors:** Ensures that recommendations are realistic and take into account the current economic environment.\n",
        "\n",
        "### 2. Based on the data you chose to use in this recommendation system, would your model be using collaborative filtering, content-based filtering, or context-based filtering? Justify why the data you selected would be suitable for your choice of filtering method.\n",
        "\n",
        "Based on the data collected, a **content-based filtering** approach would be most suitable for this recommendation system.\n",
        "\n",
        "#### Justification:\n",
        "- **Content-based filtering** relies on the attributes of both users (students) and items (loans) to make recommendations. Given the extensive data on student demographics, academic information, financial background, and detailed loan characteristics, content-based filtering can effectively match students with loan options that best meet their specific needs.\n",
        "- **Collaborative filtering** is less suitable here because it relies on user interactions and similarities between users, which might be sparse in the context of student loans, as not all students will have extensive borrowing histories or relevant interactions.\n",
        "- **Context-based filtering** could be a secondary method, incorporating external factors like economic indicators and legislation changes to refine recommendations further. However, the primary matching will still be content-based due to the detailed user and item attributes available.\n",
        "\n",
        "### 3. Describe two real-world challenges that you would take into consideration while building a recommendation system for student loans. Explain why these challenges would be of concern for a student loan recommendation system.\n",
        "\n",
        "#### 1. Data Privacy and Security:\n",
        "- **Challenge:** Handling sensitive personal and financial information of students requires strict adherence to data privacy laws and regulations (e.g., GDPR, FERPA).\n",
        "- **Concern:** Any breach of this data could lead to severe consequences for students, including identity theft and financial loss. Ensuring robust data encryption, secure storage, and compliance with privacy laws is critical to maintaining trust and legal compliance.\n",
        "\n",
        "#### 2. Bias and Fairness:\n",
        "- **Challenge:** Ensuring that the recommendation system does not inadvertently favor or disadvantage certain groups of students based on their demographics, background, or other attributes.\n",
        "- **Concern:** If the system shows bias, it could result in unequal access to loan options, further exacerbating existing inequalities. For example, if the system favors students with higher credit scores disproportionately, it might not provide adequate options for students from lower-income backgrounds who may have lower credit scores but still need financial assistance for their education. Ensuring fairness in recommendations is crucial to support all students equitably.\n",
        "\n",
        "#### Additional Considerations:\n",
        "- **Regulatory Compliance:** Ensuring that the recommendation system complies with all relevant laws and regulations regarding student loans and financial advice.\n",
        "- **Economic Volatility:** Accounting for economic changes that might affect loan terms and repayment capacities, ensuring that recommendations remain relevant and realistic over time.\n",
        "\n",
        "By addressing these challenges, the recommendation system can provide reliable, fair, and secure loan options to students, helping them make informed financial decisions for their education."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Credits\n",
        "\n",
        "This project was developed with the assistance and resources provided by OpenAI's GPT-4. The use of OpenAI's technology facilitated the creation of a robust recommendation system and comprehensive documentation.\n",
        "\n",
        "### Acknowledgements\n",
        "\n",
        "- **OpenAI:** For providing the powerful language model, GPT-4, which was instrumental in generating insights, structuring the recommendation system, and drafting detailed explanations and code.\n",
        "- **Developers and Researchers at OpenAI:** For their continuous efforts in advancing artificial intelligence and natural language processing, making tools like GPT-4 accessible for educational and professional projects.\n",
        "\n",
        "### Tools and Libraries\n",
        "\n",
        "- **Python:** Used for coding and implementing the recommendation system.\n",
        "- **Pandas and NumPy:** For data manipulation and analysis.\n",
        "- **Scikit-Learn:** For machine learning algorithms and evaluation metrics.\n",
        "- **Keras:** For building and training the neural network models.\n",
        "\n",
        "### Contact Information\n",
        "\n",
        "For any questions or further information about this project, please contact:\n",
        "\n",
        "- **Project Author:** [Your Name]\n",
        "- **Email:** [Your Email]\n",
        "\n",
        "### Disclaimer\n",
        "\n",
        "This project is for educational purposes and does not constitute financial advice. The recommendations generated by this system are based on the data and methods described and should be used as a guide only. Always consult a financial advisor before making any significant financial decisions.\n",
        "\n",
        "---\n",
        "\n",
        "Thank you for reviewing this project!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
